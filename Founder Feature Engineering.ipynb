{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "949f687d",
   "metadata": {},
   "source": [
    "## Prepare each founder details into a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "125a6ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def process_csv_to_json(readFile_path, writeFile_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(readFile_path)\n",
    "\n",
    "    # Check if 'json_string' column exists\n",
    "    if 'json_string' not in df.columns:\n",
    "        raise ValueError(\"The CSV file does not contain 'json_string' column\")\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        #if index>5: break\n",
    "        # Extract the JSON string\n",
    "        json_str = str(row['json_string'])\n",
    "\n",
    "        # Parse the JSON string\n",
    "        try:\n",
    "            json_data = json.loads(json_str)\n",
    "        except:\n",
    "            print(f\"Invalid JSON format in row {index}\")\n",
    "            continue\n",
    "\n",
    "        # Write JSON data to a file\n",
    "        with open(f'{writeFile_path}/{index}.json', 'w') as json_file:\n",
    "            json.dump(json_data, json_file, indent=4)\n",
    "\n",
    "        if index % 100 == 0:\n",
    "            print(f\"Row {index} processed and saved as '{index}.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6686ea37",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 processed and saved as '0.json'\n",
      "Row 100 processed and saved as '100.json'\n",
      "Row 200 processed and saved as '200.json'\n",
      "Row 300 processed and saved as '300.json'\n",
      "Row 400 processed and saved as '400.json'\n",
      "Row 500 processed and saved as '500.json'\n",
      "Row 600 processed and saved as '600.json'\n",
      "Row 700 processed and saved as '700.json'\n",
      "Row 800 processed and saved as '800.json'\n",
      "Row 900 processed and saved as '900.json'\n",
      "Row 1000 processed and saved as '1000.json'\n",
      "Row 1100 processed and saved as '1100.json'\n",
      "Row 1200 processed and saved as '1200.json'\n",
      "Row 1300 processed and saved as '1300.json'\n",
      "Row 1400 processed and saved as '1400.json'\n",
      "Row 1500 processed and saved as '1500.json'\n",
      "Row 1600 processed and saved as '1600.json'\n",
      "Row 1700 processed and saved as '1700.json'\n",
      "Row 1800 processed and saved as '1800.json'\n",
      "Row 1900 processed and saved as '1900.json'\n",
      "Row 2000 processed and saved as '2000.json'\n",
      "Row 2100 processed and saved as '2100.json'\n",
      "Invalid JSON format in row 2106\n",
      "Row 2200 processed and saved as '2200.json'\n",
      "Row 2300 processed and saved as '2300.json'\n",
      "Row 2400 processed and saved as '2400.json'\n",
      "Row 2500 processed and saved as '2500.json'\n",
      "Row 2600 processed and saved as '2600.json'\n",
      "Row 2700 processed and saved as '2700.json'\n",
      "Row 2800 processed and saved as '2800.json'\n",
      "Row 2900 processed and saved as '2900.json'\n",
      "Row 3000 processed and saved as '3000.json'\n",
      "Row 3100 processed and saved as '3100.json'\n",
      "Row 3200 processed and saved as '3200.json'\n",
      "Row 3300 processed and saved as '3300.json'\n",
      "Row 3400 processed and saved as '3400.json'\n",
      "Row 3500 processed and saved as '3500.json'\n",
      "Row 3600 processed and saved as '3600.json'\n",
      "Row 3700 processed and saved as '3700.json'\n",
      "Row 3800 processed and saved as '3800.json'\n",
      "Row 3900 processed and saved as '3900.json'\n",
      "Row 4000 processed and saved as '4000.json'\n",
      "Row 0 processed and saved as '0.json'\n",
      "Row 100 processed and saved as '100.json'\n",
      "Row 200 processed and saved as '200.json'\n",
      "Row 300 processed and saved as '300.json'\n",
      "Row 400 processed and saved as '400.json'\n",
      "Row 500 processed and saved as '500.json'\n",
      "Row 600 processed and saved as '600.json'\n",
      "Row 700 processed and saved as '700.json'\n",
      "Row 800 processed and saved as '800.json'\n",
      "Row 900 processed and saved as '900.json'\n",
      "Row 1000 processed and saved as '1000.json'\n",
      "Row 1100 processed and saved as '1100.json'\n",
      "Row 1200 processed and saved as '1200.json'\n",
      "Row 1300 processed and saved as '1300.json'\n",
      "Row 1400 processed and saved as '1400.json'\n",
      "Row 1500 processed and saved as '1500.json'\n",
      "Row 1600 processed and saved as '1600.json'\n",
      "Row 1700 processed and saved as '1700.json'\n",
      "Row 1800 processed and saved as '1800.json'\n",
      "Row 1900 processed and saved as '1900.json'\n",
      "Row 2000 processed and saved as '2000.json'\n",
      "Row 2100 processed and saved as '2100.json'\n",
      "Row 2200 processed and saved as '2200.json'\n",
      "Row 2300 processed and saved as '2300.json'\n",
      "Row 2400 processed and saved as '2400.json'\n",
      "Row 2500 processed and saved as '2500.json'\n",
      "Row 2600 processed and saved as '2600.json'\n",
      "Row 2700 processed and saved as '2700.json'\n",
      "Row 2800 processed and saved as '2800.json'\n",
      "Row 2900 processed and saved as '2900.json'\n",
      "Row 3000 processed and saved as '3000.json'\n",
      "Row 3100 processed and saved as '3100.json'\n",
      "Row 3200 processed and saved as '3200.json'\n",
      "Row 3300 processed and saved as '3300.json'\n",
      "Row 3400 processed and saved as '3400.json'\n",
      "Row 3500 processed and saved as '3500.json'\n",
      "Row 3600 processed and saved as '3600.json'\n",
      "Row 3700 processed and saved as '3700.json'\n",
      "Row 3800 processed and saved as '3800.json'\n",
      "Row 3900 processed and saved as '3900.json'\n",
      "Row 4000 processed and saved as '4000.json'\n",
      "Row 4100 processed and saved as '4100.json'\n",
      "Row 4200 processed and saved as '4200.json'\n",
      "Row 4300 processed and saved as '4300.json'\n",
      "Row 4400 processed and saved as '4400.json'\n",
      "Row 4500 processed and saved as '4500.json'\n",
      "Row 4600 processed and saved as '4600.json'\n",
      "Row 4700 processed and saved as '4700.json'\n",
      "Row 4800 processed and saved as '4800.json'\n",
      "Row 4900 processed and saved as '4900.json'\n",
      "Row 5000 processed and saved as '5000.json'\n",
      "Row 5100 processed and saved as '5100.json'\n",
      "Row 5200 processed and saved as '5200.json'\n",
      "Row 5300 processed and saved as '5300.json'\n",
      "Row 5400 processed and saved as '5400.json'\n",
      "Row 5500 processed and saved as '5500.json'\n",
      "Row 5600 processed and saved as '5600.json'\n",
      "Row 5700 processed and saved as '5700.json'\n",
      "Row 5800 processed and saved as '5800.json'\n",
      "Row 5900 processed and saved as '5900.json'\n"
     ]
    }
   ],
   "source": [
    "successProfilePath = 'founder-data/success_enriched_linkedin_profiles.csv'\n",
    "successDataDirectory = 'founder-data/successful-founders'\n",
    "failProfilePath = 'founder-data/fail_enriched_linkedin_profiles.csv'\n",
    "failDataDirectory = 'founder-data/failed-founders'\n",
    "\n",
    "process_csv_to_json(successProfilePath, successDataDirectory)\n",
    "process_csv_to_json(failProfilePath, failDataDirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722dacf2",
   "metadata": {},
   "source": [
    "## Extract founder's company and their description based on founder_profile_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ee920700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_company_info(founder_linkedin_url, xls):\n",
    "    # Load the spreadsheet\n",
    "    #xls = pd.ExcelFile(spreadsheet_path)\n",
    "\n",
    "    # Load the specific worksheets\n",
    "    df_linkedin = pd.read_excel(xls, 'Founder Linkedin URLs')\n",
    "    df_company = pd.read_excel(xls, 'Long company descriptions')\n",
    "    df_company_details = pd.read_excel(xls, 'Company')\n",
    "\n",
    "    # Find the organisation id corresponding to the input url\n",
    "    if founder_linkedin_url in df_linkedin['founder_linkedin_url'].values:\n",
    "        org_uuid = df_linkedin[df_linkedin['founder_linkedin_url'] == founder_linkedin_url]['org_uuid'].iloc[0]\n",
    "    else:\n",
    "        return {\"URL Error\" : \"LinkedIn URL not found in the dataset.\"}\n",
    "\n",
    "    # Initialize dictionary to hold all the required information\n",
    "    company_info = {}\n",
    "\n",
    "    # Find the org_name and long description using the org_uuid\n",
    "    if org_uuid in df_company['org_uuid'].values:\n",
    "        company_description_info = df_company[df_company['org_uuid'] == org_uuid][['org_name', 'long_description']].iloc[0]\n",
    "        company_info.update(company_description_info.to_dict())\n",
    "    else:\n",
    "        company_info[\"org_name\"] = \"Not found\"\n",
    "        company_info[\"long_description\"] = \"Not found\"\n",
    "\n",
    "    # Find the additional attributes from the \"Company\" worksheet\n",
    "    if org_uuid in df_company_details['org_uuid'].values:\n",
    "        company_additional_info = df_company_details[df_company_details['org_uuid'] == org_uuid][['category_list', 'category_groups_list', 'country_code', 'city']].iloc[0]\n",
    "        company_info.update(company_additional_info.to_dict())\n",
    "    else:\n",
    "        company_info[\"category_list\"] = \"Not found\"\n",
    "        company_info[\"category_groups_list\"] = \"Not found\"\n",
    "        company_info[\"country_code\"] = \"Not found\"\n",
    "        company_info[\"city\"] = \"Not found\"\n",
    "\n",
    "    return company_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2cd20c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'org_name': '1inch',\n",
       " 'long_description': '1inch Limited builds decentralized protocols and contributes to the development of the 1inch Network. The synergy of 1inch protocols, including the 1inch Aggregation Protocol, the 1inch Liquidity Protocol and the 1inch Limit Order Protocol, enables the most lucrative, fastest and protected operations in DeFi.',\n",
       " 'category_list': 'Blockchain,Cryptocurrency,Information Services,Information Technology,Open Source,Software',\n",
       " 'category_groups_list': 'Financial Services,Information Technology,Other,Payments,Software',\n",
       " 'country_code': 'KNA',\n",
       " 'city': 'Old Road Town'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage:\n",
    "xls = pd.ExcelFile('founder-data/Moneyball 1.1_ Success.xlsx')\n",
    "result = find_company_info('https://linkedin.com/in/k06aa', xls)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ee7e67",
   "metadata": {},
   "source": [
    "## Extract relevant features from the JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6bbb47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "def extract_founder_details(json_filename):\n",
    "    \"\"\"\n",
    "    A combined function to extract various attributes of a founder from a JSON file.\n",
    "    Attributes include name, gender, age, self-description, education backgrounds, and employment backgrounds.\n",
    "\n",
    "    Parameters:\n",
    "    json_filename (str): The filename of the JSON file\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing all the extracted attributes of the founder\n",
    "    \"\"\"\n",
    "    def timestamp_to_datetime(timestamp):\n",
    "        \"\"\"\n",
    "        Helper function to convert timestamp (in milliseconds) to datetime object.\n",
    "        \"\"\"\n",
    "        return datetime.fromtimestamp(timestamp / 1000)\n",
    "\n",
    "    def extract_education_details(person_info):\n",
    "        educations = person_info.get('educations', [])\n",
    "        education_details = []\n",
    "\n",
    "        for education in educations:\n",
    "            institution_name = education.get('institution', {}).get('name', 'N/A')\n",
    "            degree_name = education.get('degree', {}).get('name', 'N/A')\n",
    "            major_name = education.get('major', {}).get('name', 'N/A')\n",
    "\n",
    "            education_details.append((institution_name, degree_name, major_name))\n",
    "\n",
    "        return education_details\n",
    "\n",
    "    def extract_employment_details(person_info):\n",
    "        employments = person_info.get('employments', [])\n",
    "        employment_details = []\n",
    "\n",
    "        for employment in employments:\n",
    "            \n",
    "            employer_name = employment.get('employer', {}).get('name', 'N/A')\n",
    "            categories = employment.get('categories', [])\n",
    "            roles = [category.get('name') for category in categories if 'name' in category]\n",
    "\n",
    "            if 'from' in employment:\n",
    "                start_timestamp = employment.get('from', {}).get('timestamp')\n",
    "                start_datetime = timestamp_to_datetime(start_timestamp)\n",
    "\n",
    "                if 'to' in employment:\n",
    "                    end_timestamp = employment.get('to', {}).get('timestamp')\n",
    "                    end_datetime = timestamp_to_datetime(end_timestamp)\n",
    "                else:\n",
    "                    end_datetime = datetime.now()\n",
    "\n",
    "                duration_years = (end_datetime - start_datetime).total_seconds() / (365 * 24 * 60 * 60)\n",
    "                start_datetime = start_datetime.strftime('%m/%d/%Y')\n",
    "                \n",
    "            else:\n",
    "                start_datetime, end_datetime, duration_years = 'N/A', 'N/A', 0.0\n",
    "                \n",
    "            is_current = employment.get('isCurrent', False)\n",
    "\n",
    "            employment_details.append((employer_name, roles, duration_years, start_datetime, is_current))\n",
    "\n",
    "        return employment_details\n",
    "\n",
    "    try:\n",
    "        # Load the JSON file\n",
    "        with open(json_filename, 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        # Extracting the 'data' key which contains the relevant information\n",
    "        person_data = data.get('data', [])\n",
    "        if not person_data or not isinstance(person_data, list) or not person_data[0]:\n",
    "            return {}\n",
    "\n",
    "        # Extracting the first element of the data list\n",
    "        person_info = person_data[0]\n",
    "\n",
    "        # Extracting various attributes\n",
    "        name = person_info.get('nameDetail', {}).get('firstName', '') + \" \" + person_info.get('nameDetail', {}).get('lastName', '')\n",
    "        gender = person_info.get('gender', {}).get('normalizedValue')\n",
    "        age = person_info.get('age')\n",
    "        self_description = person_info.get('description', \"\")\n",
    "        education_details = extract_education_details(person_info)\n",
    "        employment_details = extract_employment_details(person_info)\n",
    "\n",
    "        return {\n",
    "            \"Name\": name,\n",
    "            \"Gender\": gender,\n",
    "            \"Age\": age,\n",
    "            \"Self-Description\": self_description,\n",
    "            \"Education Backgrounds\": education_details,\n",
    "            \"Employment Backgrounds\": employment_details\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return {\"JSON Error\" : \"Founder Detail Error\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9a1eed61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'Brian Belcher',\n",
       " 'Gender': 'Male',\n",
       " 'Age': 36,\n",
       " 'Self-Description': 'Brian Belcher is a COO and Co-Founder at Vector. He Attended Santa Clara University Leavey School of Business.',\n",
       " 'Education Backgrounds': [('Eastlake High School', 'N/A', 'N/A'),\n",
       "  ('Santa Clara University Leavey School of Business',\n",
       "   'Commerce',\n",
       "   'Finance & Economics')],\n",
       " 'Employment Backgrounds': [('Vector',\n",
       "   ['Chief Officer',\n",
       "    'Management',\n",
       "    'Leadership',\n",
       "    'Executive',\n",
       "    'Founder',\n",
       "    'COO'],\n",
       "   8.79485781154896,\n",
       "   '03/01/2015',\n",
       "   True),\n",
       "  ('Addepar',\n",
       "   ['Management', 'Executive', 'Director', 'Sales'],\n",
       "   1.2465753424657535,\n",
       "   '12/01/2013',\n",
       "   False),\n",
       "  ('Addepar',\n",
       "   ['Management', 'Executive', 'Director'],\n",
       "   2.589041095890411,\n",
       "   '05/01/2011',\n",
       "   False),\n",
       "  ('Computod@s',\n",
       "   ['Management', 'Executive', 'Founder', 'Leadership'],\n",
       "   1.3342465753424657,\n",
       "   '09/01/2009',\n",
       "   False),\n",
       "  ('Mercado Global', ['Finance'], 0.5863013698630137, '06/01/2009', False),\n",
       "  ('Santa Clara University Endowment Fund',\n",
       "   ['Finance'],\n",
       "   0.7479452054794521,\n",
       "   '09/01/2008',\n",
       "   False),\n",
       "  ('Deloitte',\n",
       "   ['Intern', 'Finance'],\n",
       "   0.25205479452054796,\n",
       "   '06/01/2008',\n",
       "   False),\n",
       "  ('Morgan Stanley', ['Finance'], 0.25205479452054796, '06/01/2007', False)]}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "file_path = 'founder-data/failed-founders/1445.json'\n",
    "founder_details = extract_founder_details(file_path)\n",
    "founder_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab13032",
   "metadata": {},
   "source": [
    "## Combine and output all features of founders\n",
    "\n",
    "Note: we encode each founder with a unique id: index_{S, F}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d1fe179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def export_all_features(isSuccess, profilePath, dataDirectory, companyPath):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(profilePath)\n",
    "    xls = pd.ExcelFile(companyPath)\n",
    "    list_of_founder_details = []\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        #if index>5: break\n",
    "        try:\n",
    "            linkedin_url = row['linkedin_url']\n",
    "\n",
    "            # Call previous function to extract founder details from JSON file\n",
    "            founder_details = extract_founder_details(dataDirectory + f'/{index}.json')\n",
    "\n",
    "            # Call previous function to extract company details given founder's linkedin_url\n",
    "            founder_company_details = find_company_info(linkedin_url, xls)\n",
    "\n",
    "            # Combine the two sets of attributes into founder_details\n",
    "            founder_details.update(founder_company_details)\n",
    "\n",
    "            # Add in additional attributes\n",
    "            if isSuccess: founder_details[\"ID\"] = str(index) + \"_S\"\n",
    "            else: founder_details[\"ID\"] = str(index) + \"_F\"\n",
    "            founder_details['linkedin_url'] = linkedin_url\n",
    "            founder_details[\"isSuccess\"] = isSuccess\n",
    "\n",
    "            list_of_founder_details.append(founder_details)\n",
    "            if index % 100 == 0:\n",
    "                print(f\"Founder {founder_details['ID']} detail created.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred in index {index}: {e}. Founder detail not added.\")\n",
    "            continue\n",
    "        \n",
    "    return list_of_founder_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d3c6bc42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Founder 0_S detail created.\n",
      "Founder 100_S detail created.\n",
      "Founder 200_S detail created.\n",
      "Founder 300_S detail created.\n",
      "Founder 400_S detail created.\n",
      "Founder 500_S detail created.\n",
      "Founder 600_S detail created.\n",
      "Founder 700_S detail created.\n",
      "Founder 800_S detail created.\n",
      "Founder 900_S detail created.\n",
      "Founder 1000_S detail created.\n",
      "Founder 1100_S detail created.\n",
      "Founder 1200_S detail created.\n",
      "Founder 1300_S detail created.\n",
      "Founder 1400_S detail created.\n",
      "Founder 1500_S detail created.\n",
      "Founder 1600_S detail created.\n",
      "Founder 1700_S detail created.\n",
      "Founder 1800_S detail created.\n",
      "Founder 1900_S detail created.\n",
      "Founder 2000_S detail created.\n",
      "Founder 2100_S detail created.\n",
      "An error occurred: [Errno 2] No such file or directory: 'founder-data/successful-founders/2106.json'\n",
      "Founder 2200_S detail created.\n",
      "Founder 2300_S detail created.\n",
      "Founder 2400_S detail created.\n",
      "Founder 2500_S detail created.\n",
      "Founder 2600_S detail created.\n",
      "Founder 2700_S detail created.\n",
      "Founder 2800_S detail created.\n",
      "Founder 2900_S detail created.\n",
      "Founder 3000_S detail created.\n",
      "Founder 3100_S detail created.\n",
      "Founder 3200_S detail created.\n",
      "Founder 3300_S detail created.\n",
      "Founder 3400_S detail created.\n",
      "Founder 3500_S detail created.\n",
      "Founder 3600_S detail created.\n",
      "Founder 3700_S detail created.\n",
      "Founder 3800_S detail created.\n",
      "Founder 3900_S detail created.\n",
      "Founder 4000_S detail created.\n",
      "Founder 0_F detail created.\n",
      "Founder 100_F detail created.\n",
      "Founder 200_F detail created.\n",
      "Founder 300_F detail created.\n",
      "Founder 400_F detail created.\n",
      "Founder 500_F detail created.\n",
      "Founder 600_F detail created.\n",
      "Founder 700_F detail created.\n",
      "Founder 800_F detail created.\n",
      "Founder 900_F detail created.\n",
      "Founder 1000_F detail created.\n",
      "Founder 1100_F detail created.\n",
      "Founder 1200_F detail created.\n",
      "Founder 1300_F detail created.\n",
      "Founder 1400_F detail created.\n",
      "Founder 1500_F detail created.\n",
      "Founder 1600_F detail created.\n",
      "Founder 1700_F detail created.\n",
      "Founder 1800_F detail created.\n",
      "Founder 1900_F detail created.\n",
      "Founder 2000_F detail created.\n",
      "Founder 2100_F detail created.\n",
      "Founder 2200_F detail created.\n",
      "Founder 2300_F detail created.\n",
      "Founder 2400_F detail created.\n",
      "Founder 2500_F detail created.\n",
      "Founder 2600_F detail created.\n",
      "Founder 2700_F detail created.\n",
      "Founder 2800_F detail created.\n",
      "Founder 2900_F detail created.\n",
      "Founder 3000_F detail created.\n",
      "Founder 3100_F detail created.\n",
      "Founder 3200_F detail created.\n",
      "Founder 3300_F detail created.\n",
      "Founder 3400_F detail created.\n",
      "Founder 3500_F detail created.\n",
      "Founder 3600_F detail created.\n",
      "Founder 3700_F detail created.\n",
      "Founder 3800_F detail created.\n",
      "Founder 3900_F detail created.\n",
      "Founder 4000_F detail created.\n",
      "Founder 4100_F detail created.\n",
      "Founder 4200_F detail created.\n",
      "Founder 4300_F detail created.\n",
      "Founder 4400_F detail created.\n",
      "Founder 4500_F detail created.\n",
      "An error occurred: year 0 is out of range\n",
      "Founder 4600_F detail created.\n",
      "Founder 4700_F detail created.\n",
      "Founder 4800_F detail created.\n",
      "Founder 4900_F detail created.\n",
      "Founder 5000_F detail created.\n",
      "Founder 5100_F detail created.\n",
      "Founder 5200_F detail created.\n",
      "Founder 5300_F detail created.\n",
      "Founder 5400_F detail created.\n",
      "Founder 5500_F detail created.\n",
      "Founder 5600_F detail created.\n",
      "Founder 5700_F detail created.\n",
      "Founder 5800_F detail created.\n",
      "Founder 5900_F detail created.\n"
     ]
    }
   ],
   "source": [
    "successProfilePath = 'founder-data/success_enriched_linkedin_profiles.csv'\n",
    "successDataDirectory = 'founder-data/successful-founders'\n",
    "sucessCompanyPath = 'founder-data/Moneyball 1.1_ Success.xlsx'\n",
    "failProfilePath = 'founder-data/fail_enriched_linkedin_profiles.csv'\n",
    "failDataDirectory = 'founder-data/failed-founders'\n",
    "failCompanyPath = 'founder-data/Moneyball 1.1_ Fail.xlsx'\n",
    "\n",
    "list_of_founder_details = export_all_features(True, \n",
    "                                              successProfilePath, \n",
    "                                              successDataDirectory, \n",
    "                                              sucessCompanyPath)\n",
    "\n",
    "list_of_founder_details += export_all_features(False,\n",
    "                                              failProfilePath, \n",
    "                                              failDataDirectory, \n",
    "                                              failCompanyPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6694bd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  isSuccess               Name Gender   Age  \\\n",
      "0         0_S       True         Ryan Johns   Male  44.0   \n",
      "1         1_S       True      Shoaib Makani   Male  38.0   \n",
      "2         2_S       True         Obaid Khan   Male  35.0   \n",
      "3         3_S       True        Alex Buttle   Male  44.0   \n",
      "4         4_S       True        Harry Jones   Male  39.0   \n",
      "...       ...        ...                ...    ...   ...   \n",
      "10061  5993_F      False        James Welsh   None  47.0   \n",
      "10062  5994_F      False        Nick Tackes   None  56.0   \n",
      "10063  5995_F      False   Akinori Takahagi   Male   NaN   \n",
      "10064  5996_F      False  Motohiro Yonesaka   Male  42.0   \n",
      "10065  5997_F      False    Matthew Tullman   None   NaN   \n",
      "\n",
      "                                           linkedin_url  \\\n",
      "0            https://www.linkedin.com/in/ryan-johns-sf/   \n",
      "1                    http://www.linkedin.com/in/smakani   \n",
      "2      https://www.linkedin.com/in/obaid-khan-b77b4357/   \n",
      "3                https://www.linkedin.com/in/alexbuttle   \n",
      "4                 http://www.linkedin.com/in/jonesharry   \n",
      "...                                                 ...   \n",
      "10061  https://www.linkedin.com/in/james-welsh-8a775363   \n",
      "10062  https://www.linkedin.com/in/nick-tackes-a5139850   \n",
      "10063              http://www.linkedin.com/in/atakahagi   \n",
      "10064               http://www.linkedin.com/in/motoyone   \n",
      "10065                https://www.linkedin.com/in/mtllmn   \n",
      "\n",
      "                                        Self-Description  \\\n",
      "0      KeepTruckin co-founder and CTO, Ryan lends his...   \n",
      "1      KeepTruckin co-founder and CEO, Shoaib has ext...   \n",
      "2      KeepTruckin co-founder and Head of Operations,...   \n",
      "3      Alex Buttle is the Co-Founder & Marketing Dire...   \n",
      "4      Harry Jones is the Co-Founder & CPO at [Motorw...   \n",
      "...                                                  ...   \n",
      "10061  James Welsh is a Founder at Molecular Match, A...   \n",
      "10062  Advisor→COO @molecularmatch, Consultant→CIO @o...   \n",
      "10063  Co-founder Moff. Product manager at Mercedes-B...   \n",
      "10064  Co-Founder Moff.  Product Manager. iOS/Android...   \n",
      "10065  Matt is co-founder & CEO of 80/20 Plants. He a...   \n",
      "\n",
      "                                   Education Backgrounds  \\\n",
      "0      [(Washington University, Master's (6 year prog...   \n",
      "1      [(Texas Academy of Mathematics and Science, N/...   \n",
      "2      [(University of California San Diego, Bachelor...   \n",
      "3      [(University College London (UCL), Bachelor's ...   \n",
      "4      [(Ravensbourne, Bachelor's (4 year program), G...   \n",
      "...                                                  ...   \n",
      "10061  [(Geisel School of Medicine at Dartmouth, PhD ...   \n",
      "10062  [(Bradley University, Bachelor's (4 year progr...   \n",
      "10063  [(Kyoto University, Bachelor's (4 year program...   \n",
      "10064  [(California State University, Extension Cours...   \n",
      "10065                                                 []   \n",
      "\n",
      "                                  Employment Backgrounds         org_name  \\\n",
      "0      [(KeepTruckin, [Engineering, IT and Software D...           Motive   \n",
      "1      [(KeepTruckin, [Chief Officer, Management, Lea...           Motive   \n",
      "2      [(KeepTruckin, [Management, Executive, Manager...           Motive   \n",
      "3      [(Appear Here, [Shareholder, Management, Execu...         Motorway   \n",
      "4      [(Motorway, [Management, Executive, Founder], ...         Motorway   \n",
      "...                                                  ...              ...   \n",
      "10061  [(MD Anderson Cancer Center, [Teaching and Aca...  Molecular Match   \n",
      "10062  [(Molecular Match, [Engineering, IT and Softwa...  Molecular Match   \n",
      "10063  [(Moff, [Chief Officer, Leadership, Founder, E...             Moff   \n",
      "10064  [(Moff, [Chief Officer, Leadership, Management...             Moff   \n",
      "10065  [(Complement Nutrients, [Chief Officer, Manage...   Modern Teacher   \n",
      "\n",
      "                                        long_description  \\\n",
      "0      Motive is a remote-first company that serves m...   \n",
      "1      Motive is a remote-first company that serves m...   \n",
      "2      Motive is a remote-first company that serves m...   \n",
      "3      With so many ways to sell your car, it can be ...   \n",
      "4      With so many ways to sell your car, it can be ...   \n",
      "...                                                  ...   \n",
      "10061  MolecularMatch is the partner of choice for li...   \n",
      "10062  MolecularMatch is the partner of choice for li...   \n",
      "10063  Moff is a gesture-controlled wearable tech bra...   \n",
      "10064  Moff is a gesture-controlled wearable tech bra...   \n",
      "10065  Modern Teacher:registered: is an educational t...   \n",
      "\n",
      "                                           category_list  \\\n",
      "0      Artificial Intelligence,Logistics,SaaS,Transpo...   \n",
      "1      Artificial Intelligence,Logistics,SaaS,Transpo...   \n",
      "2      Artificial Intelligence,Logistics,SaaS,Transpo...   \n",
      "3      Automotive,Consumer Reviews,E-Commerce,Electri...   \n",
      "4      Automotive,Consumer Reviews,E-Commerce,Electri...   \n",
      "...                                                  ...   \n",
      "10061                                Health Care,Medical   \n",
      "10062                                Health Care,Medical   \n",
      "10063  Apps,Beauty,Elderly,Health Care,Internet of Th...   \n",
      "10064  Apps,Beauty,Elderly,Health Care,Internet of Th...   \n",
      "10065                          EdTech,Education,Software   \n",
      "\n",
      "                                    category_groups_list country_code  \\\n",
      "0      Artificial Intelligence,Data and Analytics,Sci...          USA   \n",
      "1      Artificial Intelligence,Data and Analytics,Sci...          USA   \n",
      "2      Artificial Intelligence,Data and Analytics,Sci...          USA   \n",
      "3                   Commerce and Shopping,Transportation          GBR   \n",
      "4                   Commerce and Shopping,Transportation          GBR   \n",
      "...                                                  ...          ...   \n",
      "10061                                        Health Care          USA   \n",
      "10062                                        Health Care          USA   \n",
      "10063  Apps,Community and Lifestyle,Consumer Goods,He...          JPN   \n",
      "10064  Apps,Community and Lifestyle,Consumer Goods,He...          JPN   \n",
      "10065                                 Education,Software          USA   \n",
      "\n",
      "                city  \n",
      "0      San Francisco  \n",
      "1      San Francisco  \n",
      "2      San Francisco  \n",
      "3             London  \n",
      "4             London  \n",
      "...              ...  \n",
      "10061        Houston  \n",
      "10062        Houston  \n",
      "10063          Tokyo  \n",
      "10064          Tokyo  \n",
      "10065        Chicago  \n",
      "\n",
      "[10066 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# Exporting to CSV file\n",
    "column_names = ['ID', 'isSuccess', 'Name', 'Gender', 'Age', 'linkedin_url',\n",
    "                'Self-Description', 'Education Backgrounds', 'Employment Backgrounds',\n",
    "                'org_name', 'long_description', 'category_list',\n",
    "                'category_groups_list','country_code', 'city']\n",
    "\n",
    "df = pd.DataFrame(list_of_founder_details, columns=column_names)\n",
    "\n",
    "df.to_csv('Founder Features.csv', index=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7dc87495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting to Excel file\n",
    "df.to_excel('Founder Features.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
